# ğŸš€ Evaluation Harness fÃ¼r Text-Vereinfachung

Eine professionelle, modulare Evaluation-Pipeline fÃ¼r die Bewertung von Modellen zur deutschen Text-Vereinfachung.

## âœ¨ Features

- ğŸ¯ **Umfassende Metriken**: SARI, Flesch-Deutsch, LIX, WSTF, Basisstatistiken
- ğŸ“Š **Statistische Analyse**: Signifikanz-Tests, EffektgrÃ¶ÃŸen, Bootstrap-Konfidenzintervalle
- ğŸ”„ **Caching**: Reproduzierbare Ergebnisse durch intelligentes Caching
- âš™ï¸ **Flexible Konfiguration**: YAML-basierte Konfiguration fÃ¼r Tasks und Modelle
- ğŸ“ˆ **Detaillierte Reports**: Markdown + JSON Ausgabe mit Visualisierungen
- ğŸ§ª **Unit Tests**: VollstÃ¤ndige Test-Abdeckung
- ğŸ“¦ **Einfache Installation**: Ein-Klick Setup

## ğŸ› ï¸ Installation

### Voraussetzungen
- Python 3.8+
- CUDA-fÃ¤hige GPU (empfohlen)
- 8GB+ RAM

### Schnellstart
```bash
# Repository klonen
git clone <repository-url>
cd evaluation_harness

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# Evaluation ausfÃ¼hren
python evaluate.py --help
```

### Manuelle Installation
```bash
pip install torch transformers numpy scipy pyyaml matplotlib seaborn tqdm
```

## ğŸš€ Verwendung

### Grundlegende Evaluation
```bash
python evaluate.py --task configs/tasks/simplify_de.yaml \
                   --models configs/models/base_phi4.yaml \
                           configs/models/finetuned_klexikon.yaml \
                   --config configs/default.yaml
```

### Erweiterte Optionen
```bash
python evaluate.py \
    --task configs/tasks/simplify_de.yaml \
    --models configs/models/base_phi4.yaml configs/models/finetuned_klexikon.yaml \
    --config configs/default.yaml \
    --verbose \
    --output outputs/custom_eval \
    --max-samples 50
```

### CLI-Optionen
- `--task`: Task-Konfigurationsdatei
- `--models`: Liste der Modell-Konfigurationsdateien
- `--config`: Haupt-Konfigurationsdatei
- `--verbose`: Detaillierte Ausgabe
- `--quiet`: Minimale Ausgabe
- `--output`: Ausgabeverzeichnis
- `--max-samples`: Maximale Anzahl Testbeispiele
- `--dry-run`: Simulation ohne echte Evaluation

## ğŸ“ Projektstruktur

```
evaluation_harness/
â”œâ”€â”€ src/                    # Haupt-Code
â”‚   â”œâ”€â”€ models.py          # Modell-Adapter
â”‚   â”œâ”€â”€ tasks.py           # Task-Management
â”‚   â”œâ”€â”€ metrics/           # Metriken
â”‚   â”‚   â”œâ”€â”€ registry.py    # Metriken-Registry
â”‚   â”‚   â”œâ”€â”€ sari.py        # SARI-Metrik
â”‚   â”‚   â””â”€â”€ readability_de.py # Deutsche Lesbarkeits-Metriken
â”‚   â”œâ”€â”€ stats.py           # Statistische Tests
â”‚   â”œâ”€â”€ report.py          # Report-Generierung
â”‚   â”œâ”€â”€ caching.py         # Caching-System
â”‚   â””â”€â”€ decoding.py        # Decoding-Strategien
â”œâ”€â”€ configs/               # Konfigurationsdateien
â”‚   â”œâ”€â”€ default.yaml       # Standard-Konfiguration
â”‚   â”œâ”€â”€ models/            # Modell-Konfigurationen
â”‚   â””â”€â”€ tasks/             # Task-Konfigurationen
â”œâ”€â”€ data/                  # Test-Daten
â”œâ”€â”€ outputs/               # Ausgabe-Ordner
â”œâ”€â”€ tests/                 # Unit Tests
â”œâ”€â”€ evaluate.py           # Haupt-Script
â”œâ”€â”€ requirements.txt      # AbhÃ¤ngigkeiten
â””â”€â”€ README.md            # Diese Datei
```

## ğŸ“Š Metriken

### Text-Vereinfachung
- **SARI**: System for Automatic Readability Index
- **Flesch-Deutsch**: Deutsche Version des Flesch-Index
- **LIX**: Lesbarkeitsindex
- **WSTF**: Wiener Sachtextformel

### Basisstatistiken
- Durchschnittliche SatzlÃ¤nge
- Durchschnittliche WortlÃ¤nge
- KomplexitÃ¤ts-VerhÃ¤ltnis
- Wort-/Satz-/Zeichenanzahl

## ğŸ“ˆ Ausgabe

### Markdown-Report (`outputs/report.md`)
- Zusammenfassung der Ergebnisse
- Detaillierte Metriken-Vergleiche
- Statistische Signifikanz-Tests
- Interpretation der Ergebnisse

### JSON-Daten (`outputs/detailed_results.json`)
- VollstÃ¤ndige Rohdaten
- Metriken pro Modell
- Statistische Tests
- Konfidenzintervalle

### Visualisierungen (`outputs/plots/`)
- Vergleichsdiagramme
- Metriken-Distributionen
- Signifikanz-Plots

## âš™ï¸ Konfiguration

### Task-Konfiguration
```yaml
task_name: simplify_de
data:
  test_file: data/test.jsonl
  dev_file: data/dev.jsonl
prompt:
  template: |
    Vereinfache den folgenden deutschen Text in einfacher Sprache (A2-B1).
    Verwende kurze SÃ¤tze und vermeide FremdwÃ¶rter.

    Text: {source}

    Vereinfachter Text:
```

### Modell-Konfiguration
```yaml
model_id: microsoft/phi-4-mini-instruct
adapter: null
```

### Haupt-Konfiguration
```yaml
seed: 42
max_new_tokens: 160
batch_size: 1
output_dir: outputs
cache_dir: .cache

decoding:
  name: greedy
  do_sample: false
  temperature: 0.0
  top_p: 1.0
```

## ğŸ§ª Tests

```bash
# Alle Tests ausfÃ¼hren
python -m pytest tests/ -v

# Mit Coverage
python -m pytest tests/ --cov=src --cov-report=html

# Spezifische Tests
python -m pytest tests/test_metrics.py -v
```

## ğŸ”§ Entwicklung

### Neue Metriken hinzufÃ¼gen
```python
# In src/metrics/registry.py
reg.register('NEUE_METRIK', lambda src, hyp, refs: neue_metrik_funktion(hyp))
```

### Neue Tasks hinzufÃ¼gen
1. Task-Konfiguration in `configs/tasks/` erstellen
2. Datenformat in `data/` bereitstellen
3. Prompt-Template definieren

### Neue Modelle hinzufÃ¼gen
1. Modell-Konfiguration in `configs/models/` erstellen
2. Bei Bedarf `ModelAdapter` erweitern

## ğŸ“Š Beispiel-Ergebnisse

```
============================================================
EVALUATION ZUSAMMENFASSUNG
============================================================
Task: simplify_de
Modelle: microsoft/phi-4-mini-instruct vs /path/to/finetuned-model
Beispiele: 50
Metriken: 10

SIGNIFIKANTE VERBESSERUNGEN:
  FLESCH_DE: +5.234 (p=0.0234)
  LIX: -3.456 (p=0.0123)

SIGNIFIKANTE VERSCHLECHTERUNGEN:
  SARI: -0.123 (p=0.0456)
```

## ğŸ› Troubleshooting

### HÃ¤ufige Probleme

**CUDA Out of Memory**
```bash
# Batch-Size reduzieren oder CPU verwenden
# In configs/default.yaml:
batch_size: 1
```

**Model Loading Fehler**
```bash
# Modell-Pfad Ã¼berprÃ¼fen
# In configs/models/:
model_id: /korrekter/pfad/zum/modell
```

**YAML Syntax Fehler**
```bash
# YAML-Validierung verwenden
python -c "import yaml; yaml.safe_load(open('configs/default.yaml'))"
```

## ğŸ¤ Beitragen

1. Fork des Repositories
2. Feature-Branch erstellen (`git checkout -b feature/AmazingFeature`)
3. Ã„nderungen committen (`git commit -m 'Add some AmazingFeature'`)
4. Branch pushen (`git push origin feature/AmazingFeature`)
5. Pull Request erstellen

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe `LICENSE` fÃ¼r Details.

## ğŸ™ Danksagungen

- Transformers Library von Hugging Face
- SciPy fÃ¼r statistische Tests
- NumPy fÃ¼r numerische Berechnungen

## ğŸ“ Support

Bei Fragen oder Problemen:
- Issue im Repository erstellen
- Dokumentation durchsuchen
- Code-Beispiele in `examples/` ansehen

---

**Version**: 1.0.0  
**Letztes Update**: 2024-09-20  
**Python**: 3.8+
